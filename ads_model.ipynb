{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import time\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import ensemble, metrics, model_selection, tree\n",
    "\n",
    "from ads_helpers import encode_labels, txt_to_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract features from the datasets\n",
    "## combine datasets\n",
    "### 0 = no attack\n",
    "### 1 = attack detected\n",
    "\n",
    "data_dir = 'test_datasets'\n",
    "dataset_filenames = {'attack_free': 'Attack_free_dataset.txt',\n",
    "                     'dos_attack': 'DoS_attack_dataset.txt',\n",
    "                     'fuzzy_attack': 'Fuzzy_attack_dataset.txt',\n",
    "                     'impersonation_attack': 'Impersonation_attack_dataset.txt'}\n",
    "\n",
    "data_dfs = {}\n",
    "for dset in dataset_filenames:\n",
    "    attack_label = 0 if dset == 'attack_free' else 1\n",
    "    dset_df = txt_to_df(dataset_filenames, data_dir, dset)\n",
    "    dset_df['Attack'] = attack_label\n",
    "    data_dfs[f'{dset}_df'] = dset_df\n",
    "data_df = pd.concat(data_dfs.values(), keys=data_dfs.keys())\n",
    "\n",
    "## preprocess non-numerical features\n",
    "data_df = encode_labels(data_df, label_lst=['ID', 'Data'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training time = 143.4360671043396 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## build ensemble model\n",
    "## modify and train model\n",
    "\n",
    "target_key = 'Attack'\n",
    "training_keys = [s for s in list(data_df.keys()) if s != target_key]\n",
    "\n",
    "x = data_df[training_keys]\n",
    "y = data_df[target_key]\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(x, y, test_size=0.1, random_state=42)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# initialize models\n",
    "dt_model = tree.DecisionTreeClassifier(random_state=42, criterion='entropy', max_leaf_nodes=1000, min_samples_leaf=2) #2750\n",
    "rf_model = ensemble.RandomForestClassifier(n_estimators=30, random_state=42, max_leaf_nodes=1000, max_features=None) #7500\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# combine predictions from multiple models with ensemble method --> majority voting scheme\n",
    "# each model \"votes\" for its predicted class and the class with the most votes becomes the final prediction\n",
    "voting_classifier = ensemble.VotingClassifier(estimators=[('decision_tree', dt_model),\n",
    "                                                          ('random_forest', rf_model),\n",
    "                                                          ('xg_boost', xgb_model)],\n",
    "                                              voting='hard') # hard for majority voting\n",
    "voting_classifier.fit(x_train, y_train)\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Model training time = {end_time - start_time} seconds\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating predictions for No Attack...\n",
      "Model Accuracy: 96.44950405770965 %\n",
      "Model Detection Rate: 95.10964049071706 %\n",
      "Model False Alarm Rate: 2.047770583474358 %\n",
      "Model F1 Score: 96.58964568125887 %\n",
      "\n",
      "Evaluating predictions for Attack Detected...\n",
      "Model Accuracy: 96.44950405770965 %\n",
      "Model Detection Rate: 97.95222941652564 %\n",
      "Model False Alarm Rate: 4.890359509282949 %\n",
      "Model F1 Score: 96.29735118199943 %\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## evaluate model\n",
    "pred = voting_classifier.predict(x_test)\n",
    "conf_matrix = metrics.confusion_matrix(y_test, pred)\n",
    "\n",
    "tp = conf_matrix.diagonal() # true positives\n",
    "tn = conf_matrix.sum() - conf_matrix.sum(axis=0) - conf_matrix.sum(axis=1) + tp # true negatives\n",
    "fp = conf_matrix.sum(axis=1) - tp # false positives\n",
    "fn = conf_matrix.sum(axis=0) - tp # false negatives\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "detection_rate = tp / (tp + fn)\n",
    "false_alarm_rate = fp / (tn + fp)\n",
    "f1 = 2*tp / (2*tp + fp + fn)\n",
    "\n",
    "for i, val in enumerate(set(y_test)):\n",
    "    if val == 0:\n",
    "        attack_type = 'No Attack'\n",
    "    elif val == 1:\n",
    "        attack_type = 'Attack Detected'\n",
    "\n",
    "    print(f\"Evaluating predictions for {attack_type}...\")\n",
    "    print(f\"Model Accuracy: {accuracy[i] * 100} %\")\n",
    "    print(f\"Model Detection Rate: {detection_rate[i] * 100} %\")\n",
    "    print(f\"Model False Alarm Rate: {false_alarm_rate[i] * 100} %\")\n",
    "    print(f\"Model F1 Score: {f1[i] * 100} %\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## export model in lightweight format\n",
    "model_name = 'ads_model'\n",
    "\n",
    "with open(f'{model_name}.pkl', 'wb') as f:\n",
    "    pickle.dump(voting_classifier, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
