{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn import (ensemble, metrics, model_selection, preprocessing, svm,\n",
    "                     tree)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to do\n",
    "## extract features from datasets\n",
    "## label each dataset by error type\n",
    "## combine datasets\n",
    "## preprocess non-numerical features\n",
    "## modify and train model\n",
    "## evaluate model\n",
    "## export model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract features from the datasets\n",
    "## assign labels to each dataset by error type\n",
    "## combine datasets\n",
    "### 0 = no attack\n",
    "### 1 = attack detected\n",
    "\n",
    "data_dir = 'test_datasets'\n",
    "dataset_filenames = {'attack_free': 'Attack_free_dataset.txt',\n",
    "                     'dos_attack': 'DoS_attack_dataset.txt',\n",
    "                     'fuzzy_attack': 'Fuzzy_attack_dataset.txt',\n",
    "                     'imperson_attack': 'Impersonation_attack_dataset.txt'}\n",
    "\n",
    "re_pattern = r'Timestamp:\\s+(\\d+\\.\\d+)\\s+ID:\\s+(\\w+)\\s+(\\w+)\\s+DLC:\\s+(\\d+)\\s+((?:\\w{2}\\s+)+)'\n",
    "null_pattern = r'Timestamp:\\s+(\\d+\\.\\d+)\\s+ID:\\s+(\\w+)\\s+(\\w+)\\s+DLC:\\s+(\\d+)'\n",
    "\n",
    "data_dfs = {}\n",
    "for dset in dataset_filenames:\n",
    "    attack_label = 0 if dset == 'attack_free' else 1\n",
    "    timestamps = []\n",
    "    ids = []\n",
    "    dlcs = []\n",
    "    data_fields = []\n",
    "    with open(f'{data_dir}/{dataset_filenames[dset]}', 'r') as f:\n",
    "        for line in f:\n",
    "            re_match = re.match(re_pattern, line)\n",
    "            if re_match:\n",
    "                timestamp, msg_id, _, dlc, data_field = re_match.groups()\n",
    "                timestamps.append(float(timestamp))\n",
    "                ids.append(msg_id)\n",
    "                dlcs.append(int(dlc))\n",
    "                data_fields.append(data_field.strip())\n",
    "            else:\n",
    "                re_match = re.match(null_pattern, line)\n",
    "                if re_match:\n",
    "                    timestamp, msg_id, _, dlc = re_match.groups()\n",
    "                    timestamps.append(float(timestamp))\n",
    "                    ids.append(msg_id)\n",
    "                    dlcs.append(int(dlc))\n",
    "                    data_fields.append('')\n",
    "\n",
    "\n",
    "    data_dfs[f'{dset}_df'] = pd.DataFrame({'Timestamp': timestamps,\n",
    "                                           'ID': ids,\n",
    "                                           'DLC': dlcs,\n",
    "                                           'Data': data_fields,\n",
    "                                           'Attack': attack_label})\n",
    "\n",
    "attack_df = pd.concat(data_dfs.values(), keys=data_dfs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocess non-numerical features\n",
    "\n",
    "label_encoder = preprocessing.LabelEncoder()\n",
    "attack_df['ID'] = label_encoder.fit_transform(attack_df['ID'])\n",
    "\n",
    "# use TF-IDF to represent features of Data in a vector space\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(attack_df['Data'])\n",
    "df_tfidf = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "attack_df = pd.concat([attack_df.reset_index(drop=True), df_tfidf], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ads_model.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## build ensemble model\n",
    "## modify and train model\n",
    "\n",
    "training_keys = set(attack_df.keys())\n",
    "exclude_keys = set(['Attack', 'Data'])\n",
    "training_keys_mod = list(training_keys - exclude_keys)\n",
    "target_key = 'Attack'\n",
    "\n",
    "x = attack_df[training_keys_mod]\n",
    "y = attack_df[target_key]\n",
    "\n",
    "num_trees = 30\n",
    "random_state = 42\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(x, y, test_size=0.3, random_state=random_state)\n",
    "\n",
    "# initialize models\n",
    "dt_model = tree.DecisionTreeClassifier(random_state=random_state)\n",
    "rf_model = ensemble.RandomForestClassifier(n_estimators=num_trees, random_state=random_state)\n",
    "xgb_model = xgb.XGBClassifier(n_estimators=num_trees, random_state=random_state)\n",
    "\n",
    "# combine predictions from multiple models with ensemble method --> majority voting scheme\n",
    "# each model \"votes\" for its predicted class and the class with the most votes becomes the final prediction\n",
    "voting_classifier = ensemble.VotingClassifier(estimators=[('decision_tree', dt_model),\n",
    "                                                          ('random_forest', rf_model),\n",
    "                                                          ('xg_boost', xgb_model)],\n",
    "                                              voting='hard') # hard for majority voting\n",
    "\n",
    "voting_classifier.fit(x_train, y_train)\n",
    "\n",
    "## export model\n",
    "joblib.dump(voting_classifier, 'ads_model.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating predictions for No Attack...\n",
      "Model Accuracy: 0.9426089859194007\n",
      "Model Detection Rate: 0.9403254266059144\n",
      "Model False Alarm Rate: 0.05494098969566259\n",
      "Model F1 Score: 0.9443229857027601\n",
      "\n",
      "Evaluating predictions for Attack Detected...\n",
      "Model Accuracy: 0.9426089859194007\n",
      "Model Detection Rate: 0.9450590103043374\n",
      "Model False Alarm Rate: 0.05967457339408559\n",
      "Model F1 Score: 0.9407861043293513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## evaluate model\n",
    "\n",
    "pred = voting_classifier.predict(x_test)\n",
    "conf_matrix = metrics.confusion_matrix(y_test, pred)\n",
    "\n",
    "tp = conf_matrix.diagonal() # true positives\n",
    "tn = conf_matrix.sum() - conf_matrix.sum(axis=0) - conf_matrix.sum(axis=1) + tp # true negatives\n",
    "fp = conf_matrix.sum(axis=1) - tp # false positives\n",
    "fn = conf_matrix.sum(axis=0) - tp # false negatives\n",
    "\n",
    "accuracy = (tp + tn) / (tp + tn + fp + fn)\n",
    "detection_rate = tp / (tp + fn)\n",
    "false_alarm_rate = fp / (tn + fp)\n",
    "f1 = 2*tp / (2*tp + fp + fn)\n",
    "\n",
    "for i, val in enumerate(set(y_test)):\n",
    "    if val == 0:\n",
    "        attack_type = 'No Attack'\n",
    "    elif val == 1:\n",
    "        attack_type = 'Attack Detected'\n",
    "\n",
    "    print(f\"Evaluating predictions for {attack_type}...\")\n",
    "    print(f\"Model Accuracy: {accuracy[i]}\")\n",
    "    print(f\"Model Detection Rate: {detection_rate[i]}\")\n",
    "    print(f\"Model False Alarm Rate: {false_alarm_rate[i]}\")\n",
    "    print(f\"Model F1 Score: {f1[i]}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
